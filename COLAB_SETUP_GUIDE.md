# ğŸš€ Google Colab Setup Guide - Automated Mining Detection

This guide will help you set up the automated training pipeline in Google Colab.

---

## ğŸ“‹ Prerequisites

âœ… Supabase account with data uploaded  
âœ… Trained U-Net model (`saved_weights.pt`)  
âœ… Google account (for Google Drive and Colab)

---

## ğŸ¯ Quick Start (5 Steps)

### **Step 1: Upload Model Weights to Google Drive**

1. Open [Google Drive](https://drive.google.com)
2. Create a folder: **`Mining_Detection`**
3. Upload your model file: **`saved_weights.pt`** (from `models/` folder)
4. Your Drive structure should look like:
   ```
   My Drive/
   â””â”€â”€ Mining_Detection/
       â””â”€â”€ saved_weights.pt  (6.5 MB)
   ```

---

### **Step 2: Open Your Existing Colab Notebook**

1. Open your notebook directly: **[https://colab.research.google.com/drive/1o4jx8GC7aDniZ0f4_zUpeQfOdg9pZn-w](https://colab.research.google.com/drive/1o4jx8GC7aDniZ0f4_zUpeQfOdg9pZn-w)**
2. The notebook is already configured with your project setup
3. No need to upload a new notebook - use the existing one!

---

### **Step 3: Connect Google Drive**

Add this cell at the **TOP** of the notebook (before Step 1):

```python
# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Copy model weights to Colab workspace
!cp /content/drive/MyDrive/Mining_Detection/saved_weights.pt ./
print("âœ… Model weights copied to Colab")
```

**Run this cell first** - it will ask permission to access your Drive.

---

### **Step 4: Update Satellite Image Path**

The notebook is already configured with your Supabase credentials. If you need to use a local test image:

1. Upload test image to Colab:
   - Click folder icon (ğŸ“) on left sidebar
   - Click upload button
   - Select `chingola_After_2025.tif`

2. Or download from Supabase:
   ```python
   # Cell already exists in notebook - no changes needed!
   # It will download from your latest Supabase upload
   ```

---

### **Step 5: Run All Cells**

1. Click **Runtime â†’ Run all** in Colab menu
2. Wait for completion (2-5 minutes depending on GPU)
3. Check output for:
   - âœ… Model loaded successfully
   - âœ… Prediction complete
   - âœ… Files uploaded to Supabase
   - âœ… Database updated

---

## ğŸ”§ Configuration (Already Done!)

Your notebook is **pre-configured** with:

```python
SUPABASE_URL = "https://ntkzaobvbsppxbljamvb.supabase.co"
SUPABASE_KEY = "eyJhbGciOiJ..."  # Your anon key
MODEL_VERSION = "UNet-v1.0"
```

âœ… No changes needed!

---

## ğŸ“Š Expected Output

After running all cells, you should see:

```
âœ… All packages installed
ğŸ“… Run timestamp: 20251106_143025
ğŸ”‘ Supabase URL: https://ntkzaobvbsppxbljamvb.supabase.co
ğŸ§  Model: UNet-v1.0

âœ… Found latest update:
   ID: 7
   Time: 2025-11-06T14:30:25
   Status: completed

ğŸ“¥ Downloading satellite imagery...
âœ… Downloaded: after.tif (0.4 MB)

ğŸ–¥ï¸  Using device: cuda
âœ… Model loaded: saved_weights.pt

ğŸ“– Loading satellite image...
   Shape: (5, 3230, 5567)
   Bands: 5
   Size: 3230 x 5567 pixels

ğŸ”® Running prediction...
âœ… Prediction complete

ğŸ“Š Prediction Statistics:
   Mining pixels: 45,230
   Mining area: 45.23 hectares
   Coverage: 0.25%

ğŸ’¾ Saved: prediction_20251106_143025.png
ğŸ’¾ Saved: prediction_20251106_143025.tif

ğŸ—ºï¸  Converting to GeoJSON...
   Found 12 polygons
   After filtering: 8 sites
   Total area: 45.23 ha
   Largest site: 12.45 ha
   Average size: 5.65 ha

âœ… Saved: mining_polygons_20251106_143025.geojson

â˜ï¸  Uploading to Supabase...
   âœ… Uploaded: prediction_20251106_143025.tif
   âœ… Uploaded: mining_polygons_20251106_143025.geojson
   âœ… Uploaded: prediction_20251106_143025.png

âœ… Database updated (Record ID: 8)

============================================================
ğŸ‰ PIPELINE COMPLETE!
============================================================

ğŸ“Š Summary:
   Mining area detected: 45.23 hectares
   Number of sites: 8
   Files uploaded: 3 (TIFF, GeoJSON, PNG)

ğŸ“± Mobile app will auto-fetch latest data on next launch

ğŸ”— Share GeoJSON URL: https://ntkzaobvbsppxbljamvb.supabase.co/storage/v1/object/public/illegal-mining-data/geojson/mining_polygons_20251106_143025.geojson
```

---

## ğŸ“± Verify in Mobile App

After Colab completes:

1. Open your Android app
2. App will auto-load the latest predictions from Supabase
3. View new mining sites on the map
4. Check analytics dashboard for updated statistics

---

## ğŸ”„ Schedule Automated Runs

### Option A: Manual (Easiest)
- Run notebook manually once a week
- Takes 2-5 minutes each time

### Option B: Google Colab Scheduled Notebooks (Colab Pro)
1. Upgrade to Colab Pro ($10/month)
2. Use scheduled notebook execution
3. Set cron schedule: Every Sunday at 2 AM

### Option C: GitHub Actions (Free)
1. Convert notebook to Python script:
   ```bash
   jupyter nbconvert --to python automated_training.ipynb
   ```
2. Create `.github/workflows/mining-detection.yml`:
   ```yaml
   name: Weekly Mining Detection
   on:
     schedule:
       - cron: '0 2 * * 0'  # Every Sunday at 2 AM
   
   jobs:
     run-detection:
       runs-on: ubuntu-latest
       steps:
         - uses: actions/checkout@v3
         - uses: actions/setup-python@v4
           with:
             python-version: '3.9'
         - run: pip install -r requirements.txt
         - run: python automated_training.py
   ```
3. Add secrets to GitHub:
   - `SUPABASE_URL`
   - `SUPABASE_KEY`

---

## ğŸ› Troubleshooting

### Issue: "Model weights not found"
**Solution:** Make sure you ran the Drive mount cell and copied `saved_weights.pt`

```python
!ls -lh saved_weights.pt  # Check if file exists
# Should show: -rw-r--r-- 1 root root 6.5M saved_weights.pt
```

---

### Issue: "No GPU available"
**Solution:** Enable GPU in Colab

1. Click **Runtime â†’ Change runtime type**
2. Hardware accelerator: **GPU** (T4)
3. Save
4. Restart runtime

---

### Issue: "Supabase upload failed"
**Solution:** Check storage bucket exists

```python
# Test bucket access
response = supabase.storage.list_buckets()
print(response)  # Should show 'illegal-mining-data'
```

---

### Issue: "Out of memory"
**Solution:** Reduce image size or use patches

```python
# Add this before prediction
if image.shape[1] > 5000 or image.shape[2] > 5000:
    print("âš ï¸  Large image detected, using tiled prediction...")
    # Use sliding window prediction (already in notebook)
```

---

## ğŸ“Š Monitoring Performance

### Check Colab Runtime
```python
# Add this cell to monitor resources
!nvidia-smi  # GPU usage
!free -h     # RAM usage
!df -h       # Disk space
```

### Expected Performance
- **GPU (T4):** 2-3 minutes for 5567Ã—3230 image
- **CPU only:** 15-20 minutes (not recommended)
- **Memory:** ~4 GB RAM, ~2 GB GPU VRAM

---

## ğŸ“š Next Steps

1. âœ… **Test the notebook** - Run all cells manually
2. âœ… **Verify uploads** - Check Supabase storage for new files
3. âœ… **Update mobile app** - Fetch latest data
4. â³ **Set up scheduling** - Choose automation method (manual, Colab Pro, or GitHub Actions)

---

## ğŸ†˜ Need Help?

Common issues:
- **Model not loading:** Check file path and Drive mount
- **Prediction failed:** Verify image format (5-band GeoTIFF)
- **Upload error:** Check Supabase credentials and bucket permissions

---

## ğŸ“ Understanding the Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   AUTOMATED PIPELINE                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚  1. Download Latest Data from Supabase                  â”‚
â”‚     â†“                                                    â”‚
â”‚  2. Load U-Net Model (saved_weights.pt)                 â”‚
â”‚     â†“                                                    â”‚
â”‚  3. Run Prediction on Satellite Image                   â”‚
â”‚     â†“                                                    â”‚
â”‚  4. Convert Binary Mask â†’ GeoJSON Polygons              â”‚
â”‚     â†“                                                    â”‚
â”‚  5. Upload Results to Supabase Storage                  â”‚
â”‚     â†“                                                    â”‚
â”‚  6. Update Database Record                              â”‚
â”‚     â†“                                                    â”‚
â”‚  7. Mobile App Auto-Fetches Latest Data                 â”‚
â”‚                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Result:** New predictions are automatically available in your mobile app without any manual updates!

---

## âœ… Checklist

Before running the notebook:

- [ ] Uploaded `saved_weights.pt` to Google Drive
- [ ] Opened notebook in Google Colab
- [ ] Added Drive mount cell at top
- [ ] Enabled GPU runtime
- [ ] Verified Supabase credentials
- [ ] Have test satellite image ready

After successful run:

- [ ] Check Colab output for âœ… success messages
- [ ] Verify files in Supabase storage (`predictions/`, `geojson/`, `visualizations/`)
- [ ] Check database for new record in `mining_updates` table
- [ ] Open mobile app to see updated predictions
- [ ] Share GeoJSON URL if needed

---

**ğŸ‰ Ready to automate your mining detection!**

For questions or issues, refer to `PHASE1_QUICKSTART.md` or the main `AUTOMATION_IMPLEMENTATION_GUIDE.md`.
